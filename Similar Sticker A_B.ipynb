{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connection and loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%init_spark\n",
    "launcher.master = \"yarn\"\n",
    "launcher.conf.spark.app.name = \"Similar_A/B\"\n",
    "launcher.conf.spark.yarn.queue=\"root.analyst.editor-bu\"\n",
    "launcher.conf.spark.executor.cores=5\n",
    "launcher.conf.spark.executor.memory=\"15g\"\n",
    "launcher.conf.spark.driver.memory=\"10g\"\n",
    "launcher.conf.spark.dynamicAllocation.enabled=\"true\"\n",
    "launcher.conf.spark.shuffle.service.enabled=\"true\"\n",
    "launcher.conf.spark.dynamicAllocation.maxExecutors=50\n",
    "launcher.jars=[\"/opt/shared/postgresql_1.jar\"]\n",
    "launcher.conf.spark.sql.shuffle.partitions=250\n",
    "launcher.conf.spark.serializer=\"org.apache.spark.serializer.KryoSerializer\"\n",
    "launcher.conf.spark.yarn.executor.memoryOverhead=\"5120m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://ny-dev-master.picsart.loc:8088/proxy/application_1567159442863_1617,http://ny-hbase-master.picsart.loc:8088/proxy/application_1567159442863_1617\n",
       "SparkContext available as 'sc' (version = 2.4.3, master = yarn, app id = application_1567159442863_1617)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.joda.time.format.DateTimeFormat\n",
       "import java.util.Properties\n",
       "import org.apache.spark.sql.DataFrame\n",
       "import org.apache.spark.sql.{DataFrame, SQLContext}\n",
       "import org.apache.spark.{SparkConf, SparkContext}\n",
       "import org.joda.time.{DateTime, Days}\n",
       "import org.apache.spark.sql.{DataFrame, SparkSession}\n",
       "import org.apache.spark.sql.SaveMode._\n",
       "import org.apache.spark.sql.expressions.Window\n",
       "import org.apache.spark.SparkConf\n",
       "import org.apache.spark.sql.SparkSession\n",
       "import org.json4s._\n",
       "import org.json4s.jackson.JsonMethods._\n",
       "import org.joda.time.format.DateTimeFormat\n",
       "import org.joda.time.{DateTime, Days}\n",
       "formatter: org.joda.time.format.DateTimeFormatter = org.joda.time.format.DateTimeFormatter@3b97b9c5\n",
       "import scala.util.Try\n",
       "import java.sql.{Connection, DriverManager, ResultSet}\n",
       "sparkSession: o..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.joda.time.format.DateTimeFormat\n",
    "import java.util.Properties\n",
    "import org.apache.spark.sql.DataFrame\n",
    "import org.apache.spark.sql.{DataFrame, SQLContext}\n",
    "import org.apache.spark.{SparkConf, SparkContext}\n",
    "import org.joda.time.{DateTime, Days}\n",
    "import org.apache.spark.sql.{DataFrame, SparkSession}\n",
    "import org.apache.spark.sql.SaveMode._\n",
    "import org.apache.spark.sql.expressions.Window\n",
    "import org.apache.spark.SparkConf\n",
    "import org.apache.spark.sql.SparkSession\n",
    "import org.json4s._\n",
    "import org.json4s.jackson.JsonMethods._\n",
    "import org.joda.time.format.DateTimeFormat\n",
    "import org.joda.time.{DateTime, Days}\n",
    "val formatter = DateTimeFormat.forPattern(\"yyyy-MM-dd\")\n",
    "\n",
    "import scala.util.Try\n",
    "import java.sql.{Connection, DriverManager, ResultSet}\n",
    "val sparkSession = SparkSession.builder.master(\"local\").appName(\"example\").getOrCreate()\n",
    "import sparkSession.implicits._      \n",
    "import org.apache.spark.SparkContext  \n",
    "\n",
    "\n",
    "val spark = SparkSession.builder().appName(\"test\").getOrCreate()\n",
    "\n",
    "val pathFormatter = DateTimeFormat.forPattern(\"yyyy/MM/dd\")\n",
    "val partitionFormatter = DateTimeFormat.forPattern(\"yyyy-MM-dd\")\n",
    "\n",
    "val props = new Properties()\n",
    "val JDBC_URL = \"jdbc:postgresql://172.16.33.44:5432/dwh\"\n",
    "\n",
    "props.setProperty(\"driver\", \"org.postgresql.Driver\")\n",
    "props.setProperty(\"max_connections\", \"10000\")\n",
    "props.setProperty(\"user\", \"dwh\")\n",
    "props.setProperty(\"password\", \"4F51hnXVMZoDcHrLvf\")\n",
    "props.setProperty(\"loginTimeout\", \"30\")\n",
    "props.setProperty(\"socketTimeout\", \"1800\")\n",
    "\n",
    "\n",
    "val sqlContext = spark\n",
    "\n",
    "\n",
    "def publish(df:DataFrame, table:String, append:Boolean): Unit = {\n",
    " val conn = DriverManager.getConnection(\"jdbc:postgresql://172.16.33.44:5432/dwh?user=dwh&password=4F51hnXVMZoDcHrLvf\")\n",
    " try{ val mode = if(append) Append else Overwrite\n",
    "  df.write.mode(mode).jdbc(JDBC_URL, table, props)\n",
    " \n",
    " }\n",
    "catch {\n",
    "            case e: Exception => \n",
    "              e.printStackTrace()\n",
    "    }\n",
    "   finally {\n",
    "    \n",
    "    conn.close\n",
    "}\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def getBigTable(from:DateTime, to:DateTime) : DataFrame = {\n",
    "  val days = Days.daysBetween(from.withTimeAtStartOfDay(), to.withTimeAtStartOfDay()).getDays\n",
    "  val files = (0 to days).map { d=>\n",
    "    val dateStr = from.plusDays(d).toString(partitionFormatter)\n",
    "    s\"/analytics/big-table/partition_date=$dateStr\"\n",
    "  }\n",
    "  spark.read.parquet(files:_*)\n",
    "}\n",
    "\n",
    "def getEvent(app:String, event:String, from:DateTime, to:DateTime, mergeSchemaOption: String = \"false\") : DataFrame = {\n",
    "  val days = Days.daysBetween(from.withTimeAtStartOfDay(), to.withTimeAtStartOfDay()).getDays\n",
    "  val files = (0 to days).map { d=>\n",
    "    val dateStr = from.plusDays(d).toString(pathFormatter)\n",
    "    s\"/analytics/events/PARQUET/mobile_events/$app/$dateStr/$event\"\n",
    "  }\n",
    "  spark.read.option(\"mergeSchema\", mergeSchemaOption).parquet(files:_*)\n",
    "}\n",
    "\n",
    "def getSocialEvent(from:DateTime, to:DateTime) : DataFrame = {\n",
    "  val days = Days.daysBetween(from.withTimeAtStartOfDay(), to.withTimeAtStartOfDay()).getDays\n",
    "  val files = (0 to days).map { d=>\n",
    "    val dateStr = from.plusDays(d).toString(pathFormatter)\n",
    "    s\"/analytics/events/PARQUET/social_events/$dateStr/\"\n",
    "  }\n",
    "  spark.read.parquet(files:_*)\n",
    "}\n",
    "\n",
    "def getActiveDevices(from:DateTime, to:DateTime): DataFrame = {\n",
    "  val days = Days.daysBetween(from.withTimeAtStartOfDay(), to.withTimeAtStartOfDay()).getDays\n",
    "  val files = (0 to days).map { d=>\n",
    "    val dateStr = from.plusDays(d).toString(pathFormatter)\n",
    "    s\"/analytics/events/PARQUET/mobile_devices/$dateStr/\"\n",
    "  }\n",
    "  spark.read.parquet(files:_*)\n",
    "}\n",
    "\n",
    "def table(app:String, event:String, from:DateTime, to:DateTime) : Unit = {\n",
    "  val days = Days.daysBetween(from.withTimeAtStartOfDay(), to.withTimeAtStartOfDay()).getDays\n",
    "  val files = (0 to days).map { d=>\n",
    "    val dateStr = from.plusDays(d).toString(pathFormatter)\n",
    "    s\"/analytics/events/PARQUET/mobile_events/$app/$dateStr/$event\"\n",
    "  }\n",
    "  spark.read.parquet(files:_*).registerTempTable(event)\n",
    "}\n",
    "\n",
    "def getEntity(entity: String): DataFrame = {\n",
    "  spark.read.parquet(s\"/analytics/entities/$entity\")\n",
    "}\n",
    "\n",
    "def getUsers() : DataFrame = {\n",
    "  getEntity(\"users\")\n",
    "}\n",
    "\n",
    "def getPhotos() : DataFrame = {\n",
    "  getEntity(\"photos\")\n",
    "}\n",
    "\n",
    "def getContests() : DataFrame = {\n",
    "  getEntity(\"contests\")\n",
    "}\n",
    "\n",
    "def getTags() : DataFrame = {\n",
    "  getEntity(\"tags\")\n",
    "}\n",
    "\n",
    "def getStreams() : DataFrame = {\n",
    "  getEntity(\"streams\")\n",
    "}\n",
    "\n",
    "def getDevices() : DataFrame = {\n",
    "  getEntity(\"device_attributes\")\n",
    "}\n",
    "\n",
    "def getRequests() : DataFrame = {\n",
    "  getEntity(\"requests\")\n",
    "}\n",
    "\n",
    "def getCommon(app:String, from:DateTime, to:DateTime) : DataFrame = {\n",
    "  getEvent(app, \"common\", from, to)\n",
    "}\n",
    "\n",
    "\n",
    "def today(): DateTime = {\n",
    "  new DateTime().withTimeAtStartOfDay()\n",
    "}\n",
    "\n",
    "def yesterday(): DateTime = {\n",
    "  today().minusDays(1)\n",
    "}\n",
    "\n",
    "def getCommonLastNDays(app:String, days:Int) : org.apache.spark.sql.DataFrame = {\n",
    "  getEvent(app, \"common\", today().minusDays(days), today())\n",
    "}\n",
    "\n",
    "def getEventLastNDays(app:String, event:String, days:Int) : DataFrame = {\n",
    "  getEvent(app, event, today().minusDays(days), today())\n",
    "}\n",
    "\n",
    "def getStringParam(name:String, default:String): String = {\n",
    "  Try(System.getenv(name)).getOrElse(default)\n",
    "}\n",
    "\n",
    "def getLongParam(name:String, default:Long): Long = {\n",
    "  Try(System.getenv(name).toLong).getOrElse(default)\n",
    "}\n",
    "\n",
    "def getDateParam(name:String, default:DateTime): DateTime = {\n",
    "  Try(pathFormatter.parseDateTime(System.getenv(name))).getOrElse(default)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def getMobileDevices(from:DateTime, to:DateTime): DataFrame = {\n",
    "  val days = Days.daysBetween(from.withTimeAtStartOfDay(), to.withTimeAtStartOfDay()).getDays\n",
    "  val files = (0 to days).map { d=>\n",
    "    val dateStr = from.plusDays(d).toString(pathFormatter)\n",
    "    s\"/analytics/events/PARQUET/mobile_devices/$dateStr/\"\n",
    "  }\n",
    "  spark.read.parquet(files:_*)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def union_events(event:Array[(String,String)], from:DateTime, to:DateTime) : DataFrame = {\n",
    "  \n",
    "  var union_base : org.apache.spark.sql.DataFrame = null\n",
    "  var query:String=\"\"\n",
    "  \n",
    "   for(d<-event)\n",
    "{\n",
    "    \n",
    "     if (d._2!=\"\")\n",
    "     {query=\"where \"+d._2}\n",
    "    else\n",
    "    query=\"\"\n",
    "\n",
    "    var second=getEvent(\"com.picsart.studio\",d._1,from,to).registerTempTable(\"second\")\n",
    "\n",
    "    var final_second = spark.sql(s\"\"\" select * from second  $query \"\"\").\n",
    "    select($\"device_id\",$\"platform\",to_date($\"timestamp\").as(\"date\"),lower($\"country_code\").as(\"country_code\"))  \n",
    "\n",
    "if(union_base==null) \n",
    "    {union_base=final_second} \n",
    "else \n",
    "    {union_base=union_base.unionAll(final_second)}\n",
    "\n",
    "}\n",
    "return union_base\n",
    "}\n",
    " \n",
    " \n",
    "def erase_table(table_name:String, condition:String =\"\") {\n",
    "   var JDBC_DRIVER = \"org.postgresql.Driver\";  \n",
    "   var DB_URL = \"jdbc:postgresql://172.16.33.44:5432/dwh\";\n",
    "   var USER = \"dwh\";\n",
    "   var PASS = \"4F51hnXVMZoDcHrLvf\";\n",
    "   var conn:java.sql.Connection = null;\n",
    "   var stmt:java.sql.Statement = null;\n",
    "   conn = java.sql.DriverManager.getConnection(DB_URL, USER, PASS);\n",
    "   stmt = conn.createStatement();\n",
    "   var sql:String = s\"DELETE FROM $table_name\" ;\n",
    "   if (condition != \"\") { sql = sql+ \" where \" + condition}\n",
    "   println(sql)\n",
    "   stmt.executeUpdate(sql);\n",
    "   stmt.close()\n",
    "}\n",
    "\n",
    "def getActive(from:DateTime, to:DateTime): DataFrame = {\n",
    "\n",
    " val days = Days.daysBetween(from.withTimeAtStartOfDay(), to.withTimeAtStartOfDay()).getDays\n",
    " var union_base : org.apache.spark.sql.DataFrame = null\n",
    "(0 to days).map { d=>\n",
    "val dateStr = from.plusDays(d).toString(pathFormatter) \n",
    "var aa=spark.read.parquet(s\"/analytics/events/PARQUET/mobile_devices/$dateStr/\").\n",
    "filter($\"app\"===\"com.picsart.studio\").\n",
    "select(\"device_id\").distinct.\n",
    "withColumn(\"date\",lit(dateStr)).\n",
    "withColumn(\"date\", regexp_replace(col(\"date\"), \"/\", \"-\")).\n",
    "groupBy(to_date($\"date\").as(\"date\")).agg(countDistinct(\"device_id\"))\n",
    "\n",
    "   \n",
    "\n",
    "if(union_base==null) \n",
    "    {union_base=aa} \n",
    "else \n",
    "    {union_base=union_base.unionAll(aa)}\n",
    "\n",
    "}\n",
    "return union_base\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Similar"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------+-----------------+\n",
      "|variant         |source     |avg(sid)         |\n",
      "+----------------+-----------+-----------------+\n",
      "|similar stickers|editor     |2.142857142857143|\n",
      "|original        |default    |38727.0          |\n",
      "|original        |editor     |4.0              |\n",
      "|similar stickers|default    |38106.4          |\n",
      "|similar stickers|more_button|9734.666666666666|\n",
      "|original        |more_button|9628.2           |\n",
      "+----------------+-----------+-----------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "from: org.joda.time.DateTime = 2019-07-09T00:00:00.000Z\n",
       "to: org.joda.time.DateTime = 2019-07-23T00:00:00.000Z\n",
       "exp: org.apache.spark.sql.DataFrame = [timestamp: timestamp, device_id: string ... 3 more fields]\n",
       "open: org.apache.spark.sql.DataFrame = [date: date, device_id: string ... 2 more fields]\n",
       "categoryk: org.apache.spark.sql.DataFrame = [timestamp: timestamp, device_id: string ... 2 more fields]\n",
       "subcategory_open: org.apache.spark.sql.DataFrame = [timestamp: timestamp, device_id: string ... 2 more fields]\n",
       "category_open: org.apache.spark.sql.DataFrame = [timestamp: timestamp, device_id: string ... 2 more fields]\n",
       "sticker_try: org.apache.spark.sql.DataFrame = [timestamp: timestamp, category: string ... 2 more fields]\n",
       "sticker_apply: org.apache.spark.sql.DataFrame = [timestamp: timestamp, c..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val from = DateTime.parse(\"2019-07-09\")\n",
    "val to = DateTime.parse(\"2019-07-23\")\n",
    "\n",
    "\n",
    "// var dates_seq : Seq[(String)] = Seq()\n",
    "\n",
    "// for (f <- 0 to Days.daysBetween(from, to).getDays()) {\n",
    "//     val b = (from.plusDays(f).toString())\n",
    "//     dates_seq = dates_seq :+ b\n",
    "// }\n",
    "\n",
    "// var dates = dates_seq.toDF(\"current_date\").select(to_date($\"current_date\").as(\"current_date\"))\n",
    "\n",
    "// var countries_arr = Array(\"am\", \"ar\",\"br\",\"ca\",\"cn\",\"co\",\"fr\",\"de\",\"in\",\"id\",\"it\",\"jp\",\"my\",\"mx\",\"ph\",\"ru\",\"kr\",\"es\",\"tr\",\"gb\",\"us\",\"vn\")\n",
    "\n",
    "\n",
    "// var countries = sqlContext.read.parquet(\"/analyst-shared/countries\").select($\"country_name\", lower($\"country_code\").as(\"country_code\"))\n",
    "\n",
    "// var users = sqlContext.read.parquet(\"/analytics/entities/users_orders\").\n",
    "//             select($\"device_id\".as(\"did\"), $\"order_id\".as(\"order_id\")).distinct().\n",
    "//             filter($\"did\".isNotNull)\n",
    "\n",
    "\n",
    "// var country_codes = getDevices().select($\"device_id\", lower($\"country_code\").as(\"country_code\")).\n",
    "//                     withColumn(\"country_code\", when(lower($\"country_code\").isin(countries_arr:_*), lower($\"country_code\")).otherwise(\"other\")).\n",
    "//                     groupBy($\"device_id\").agg(first($\"country_code\").as(\"country_code\")).distinct().\n",
    "//                     join(users, $\"device_id\" === $\"did\", \"inner\").\n",
    "//                     select($\"did\", $\"order_id\", $\"country_code\").distinct()\n",
    "\n",
    "\n",
    "// var orders = sqlContext.read.parquet(\"/analytics/entities/orders\").\n",
    "//             withColumn(\"platform\", \n",
    "//                 when(($\"market\" === \"google\"), lit(\"android\")).\n",
    "//                 when(($\"market\" === \"apple\"), lit(\"apple\")).\n",
    "//                 otherwise(lit(\"other\"))).\n",
    "//             filter($\"platform\"===\"apple\").as(\"a\").\n",
    "//                 join(country_codes.as(\"b\"),$\"b.order_id\" === $\"a._id\", \"inner\")./*drop($\"b.order_id\").*/\n",
    "//                 select(\n",
    "//                     $\"a._id\", $\"b.country_code\", $\"b.order_id\", $\"b.did\", \n",
    "//                     $\"a.platform\", $\"events\", $\"renewals\").as(\"a\").\n",
    "//                     join(countries.as(\"b\"), $\"a.country_code\" === $\"b.country_code\", \"left\").\n",
    "//                 select($\"order_id\", $\"_id\", $\"did\", $\"platform\", $\"events\", $\"renewals\", when($\"b.country_code\".isNotNull, $\"b.country_name\").otherwise(lit(\"Other\")).as(\"country\")).\n",
    "//                 drop($\"order_id\")\n",
    "\n",
    "\n",
    "// var orders_rn = orders.\n",
    "//                 select($\"_id\", $\"did\", $\"platform\", $\"country\", $\"events\", explode($\"renewals\").as(\"rn\")).\n",
    "//                 select($\"_id\", $\"did\", $\"platform\", $\"country\", $\"events\", $\"rn.purchaseDate\".as(\"RN_purchase\"), $\"rn.expireDate\".as(\"RN_expire\"), $\"rn.paymentStatus\".as(\"RN_status\")).\n",
    "//                 withColumn(\"dif\", round(($\"RN_expire\".cast(\"long\") - $\"RN_purchase\".cast(\"long\"))/24D/3600D, 0)).\n",
    "//                 filter($\"dif\" >= 6 && $\"RN_status\" === \"PAID\")\n",
    "    \n",
    "// var orders_ev = orders. \n",
    "//                 select($\"_id\", $\"did\",  $\"platform\", $\"country\", $\"renewals\", explode($\"events\").as(\"ev\")).\n",
    "//                 select($\"_id\", $\"did\",  $\"platform\", $\"country\", $\"renewals\", $\"ev.timestamp\".as(\"rf_date\"), $\"ev.eventType\".as(\"event\")).\n",
    "//                 filter($\"event\" === \"SUBSCRIPTION_REFUNDED\")\n",
    "\n",
    "\n",
    "// var orders_without_refunds = orders_rn.as(\"a\").join(orders_ev.as(\"b\"), $\"a._id\" === $\"b._id\" && $\"rf_date\" >= $\"RN_purchase\" && $\"rf_date\" <= $\"RN_expire\", \"left\").\n",
    "//                             select($\"a._id\", $\"a.did\", $\"a.platform\", $\"a.country\", $\"RN_status\".as(\"status\"), $\"RN_purchase\".as(\"start\"),\n",
    "//                             when($\"rf_date\".isNotNull, $\"rf_date\").otherwise($\"RN_expire\").as(\"finish\"))\n",
    "\n",
    "\n",
    "\n",
    "// var in_grace =  orders.filter(array_contains($\"events.eventType\", \"SUBSCRIPTION_IN_GRACE_PERIOD\")).\n",
    "//                 select($\"_id\", $\"did\", $\"platform\", $\"country\", $\"renewals\", explode($\"events\").as(\"ev\")).\n",
    "//                 select($\"_id\", $\"did\", $\"platform\", $\"country\", $\"renewals\", to_date($\"ev.timestamp\").as(\"GP_start\"), $\"ev.timestamp\".as(\"timestamp\"), $\"ev.eventType\".as(\"event\")).\n",
    "//                 withColumn(\"GP_next_event\", lead($\"event\", 1).over(Window.partitionBy($\"_id\").orderBy($\"timestamp\"))).\n",
    "//                 withColumn(\"GP_next_event_timestamp\", lead($\"GP_start\", 1).over(Window.partitionBy($\"_id\").orderBy($\"timestamp\"))).\n",
    "//                 withColumn(\"GP_start_plus7\", when($\"event\" === \"SUBSCRIPTION_IN_GRACE_PERIOD\", date_add($\"GP_start\",7))).\n",
    "//                 filter($\"event\" === \"SUBSCRIPTION_IN_GRACE_PERIOD\").\n",
    "//                 withColumn(\"min\", when($\"GP_start_plus7\".gt($\"GP_next_event_timestamp\"), $\"GP_next_event_timestamp\").otherwise($\"GP_start_plus7\")).\n",
    "//                 withColumn(\"GP_finish\", \n",
    "//                 when($\"GP_next_event\".isNotNull, $\"min\").\n",
    "//                 when($\"GP_next_event\".isNull, $\"GP_start_plus7\")).\n",
    "//                 select($\"_id\", $\"did\", $\"platform\", $\"country\", lit(\"In_Grace_Period\").as(\"status\"), $\"GP_start\".as(\"start\"), $\"GP_finish\".as(\"finish\"))\n",
    "\n",
    "\n",
    "// var all_active_users = orders_without_refunds.unionAll(in_grace).\n",
    "//                         select($\"_id\", $\"did\", $\"platform\", $\"country\", $\"status\", to_date($\"start\").as(\"start\"), to_date($\"finish\").as(\"finish\"))\n",
    "\n",
    "\n",
    "// var actives = dates.as(\"a\").join(all_active_users.as(\"b\"), $\"a.current_date\" >= $\"b.start\" && $\"a.current_date\" <= $\"b.finish\", \"left\").\n",
    "//                 select($\"current_date\", $\"_id\", $\"did\", $\"b.platform\", $\"country\")\n",
    "                \n",
    "// val installs = sqlContext.read.parquet(\"/analytics/entities/installs\")\n",
    "//     .filter($\"app\"===\"com.picsart.studio\")\n",
    "//     .select(to_date($\"timestamp\").as(\"install_date\"), $\"device_id\")\n",
    "//     .groupBy($\"device_id\")\n",
    "//     .agg(min($\"install_date\").as(\"install_date\"))\n",
    "//     .select($\"install_date\", $\"device_id\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "// val experiment = getEvent(\"com.picsart.studio\", \"experiment_participate\", from, to)\n",
    "//     .filter($\"experiment_id\" === \"97de\" && $\"platform\"=== \"apple\")\n",
    "//     .select($\"timestamp\", $\"device_id\", $\"variant\", $\"country_code\")\n",
    "//     .groupBy($\"device_id\", $\"variant\", $\"country_code\").agg(min($\"timestamp\").as(\"timestamp\"))\n",
    "//     .select($\"timestamp\", $\"device_id\", $\"variant\", lower($\"country_code\").as(\"cc\"))\n",
    "//     .as(\"a\")\n",
    "//     .join(installs.as(\"b\"), $\"a.device_id\" === $\"b.device_id\" && to_date($\"a.timestamp\") === $\"b.install_date\", \"left\")\n",
    "//     .select($\"a.timestamp\", $\"a.device_id\", $\"a.variant\", (when($\"b.device_id\".isNull, lit(false)).otherwise(lit(true))).as(\"is_new\"))\n",
    "//     .as(\"a\")\n",
    "//     .join(actives.as(\"b\"), $\"a.device_id\"===$\"b.did\" && to_date($\"a.timestamp\") === $\"b.current_date\", \"left\")\n",
    "//     .select($\"a.timestamp\", $\"a.device_id\", $\"a.variant\", $\"a.is_new\",(when($\"b.did\".isNull, lit(false)).otherwise(lit(true))).as(\"is_subscribed\"))\n",
    "//     .write.mode(org.apache.spark.sql.SaveMode.Overwrite).parquet(\"/user/nare.silanyan/exp\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "// val participation = exp.groupBy(to_date($\"timestamp\").as(\"date\"), $\"is_new\", $\"is_subscribed\").pivot(\"variant\").agg(countDistinct($\"device_id\")).orderBy($\"date\").show(100,false)\n",
    "\n",
    "val exp = sqlContext.read.parquet(\"/user/nare.silanyan/exp\")\n",
    "\n",
    "\n",
    "val open = getEvent(\"com.picsart.studio\", \"edit_item_open\", from, to).\n",
    "    filter($\"item\"===\"sticker\" && $\"origin\"===\"editor\").\n",
    "    select(to_date($\"timestamp\").as(\"date\"), $\"device_id\", $\"editor_sid\", $\"source\")\n",
    "\n",
    "val categoryk = getEvent(\"com.picsart.studio\", \"edit_sticker_category_open\", from, to).\n",
    "    filter($\"origin\" === \"editor\" && $\"platform\" === \"apple\" && $\"editor_sid\".isNotNull).\n",
    "    select($\"timestamp\", $\"device_id\", $\"editor_sid\", $\"source\")\n",
    "\n",
    "\n",
    "val subcategory_open = getEvent(\"com.picsart.studio\", \"edit_sticker_subcategory_open\", from, to).\n",
    "    filter($\"origin\" === \"editor\" && $\"platform\" === \"apple\" && $\"editor_sid\".isNotNull).\n",
    "    select($\"timestamp\", $\"device_id\", $\"editor_sid\", $\"source\")\n",
    "\n",
    "\n",
    "val category_open = categoryk.unionAll(subcategory_open).\n",
    "    select($\"timestamp\", $\"device_id\", $\"editor_sid\", $\"source\")\n",
    "\n",
    "val sticker_try = getEvent(\"com.picsart.studio\", \"edit_sticker_try\", from, to).\n",
    "    filter($\"origin\"===\"editor\" && $\"platform\" === \"apple\" && $\"editor_sid\".isNotNull).\n",
    "    select($\"timestamp\", $\"category\", $\"device_id\", $\"editor_sid\")\n",
    "\n",
    "\n",
    "val sticker_apply = getEvent(\"com.picsart.studio\", \"edit_sticker_apply\", from, to).\n",
    "    filter($\"origin\" === \"editor\" && $\"platform\" === \"apple\" && $\"editor_sid\".isNotNull).\n",
    "    select($\"timestamp\", $\"category\", $\"device_id\", $\"editor_sid\", $\"source\")\n",
    "\n",
    "\n",
    "val editor_done = getEvent(\"com.picsart.studio\", \"editor_done_click\", from, to).\n",
    "    filter($\"platform\" === \"apple\" && $\"editor_sid\".isNotNull).\n",
    "    select($\"device_id\", $\"editor_sid\").distinct()\n",
    "\n",
    "\n",
    "\n",
    "val funnel = exp\n",
    "    .as(\"a\")\n",
    "    .join(category_open.as(\"b\"), $\"a.device_id\" === $\"b.device_id\" && $\"a.timestamp\" <= $\"b.timestamp\", \"inner\")\n",
    "    .select(to_date($\"b.timestamp\").as(\"date\"), $\"b.device_id\", $\"b.editor_sid\", $\"a.variant\", $\"a.is_new\", $\"a.is_subscribed\")\n",
    "    .as(\"a\")\n",
    "    .join(sticker_try.as(\"b\"), $\"a.editor_sid\" === $\"b.editor_sid\", \"left\")\n",
    "    .select(\n",
    "        $\"a.date\",$\"a.variant\", $\"a.is_new\", $\"a.is_subscribed\",\n",
    "        $\"a.device_id\".as(\"open_dv\"), $\"a.editor_sid\".as(\"open_sid\"), \n",
    "        $\"b.device_id\".as(\"try_dv\"), $\"b.editor_sid\".as(\"try_sid\"))  \n",
    "    .as(\"c\")\n",
    "    .join(sticker_apply.as(\"d\"), $\"c.try_sid\" === $\"d.editor_sid\", \"left\")\n",
    "    .select(\n",
    "        $\"c.date\", $\"c.variant\", $\"c.is_new\", $\"c.is_subscribed\",\n",
    "        $\"c.open_dv\", $\"c.open_sid\", \n",
    "        $\"c.try_dv\", $\"c.try_sid\", \n",
    "        $\"d.device_id\".as(\"apply_dv\"), \n",
    "        $\"d.editor_sid\".as(\"apply_sid\"))\n",
    "    .groupBy($\"date\", $\"variant\", $\"is_new\", $\"is_subscribed\")\n",
    "    .agg(\n",
    "        countDistinct($\"open_sid\").as(\"open_sid\"),\n",
    "        countDistinct($\"open_dv\").as(\"open_dv\"),\n",
    "        countDistinct($\"try_sid\").as(\"try_sid\"),\n",
    "        countDistinct($\"try_dv\").as(\"try_dv\"),\n",
    "        countDistinct($\"apply_sid\").as(\"apply_sid\"),\n",
    "        countDistinct($\"apply_dv\").as(\"apply_dv\"))\n",
    "\n",
    "   \n",
    "\n",
    "val try_apply_category =exp\n",
    "    .as(\"a\")\n",
    "    .join(sticker_try.as(\"b\"), $\"a.device_id\" === $\"b.device_id\" && $\"a.timestamp\" <= $\"b.timestamp\", \"inner\")\n",
    "    .select(to_date($\"b.timestamp\").as(\"date\"), $\"b.device_id\", $\"b.editor_sid\", $\"a.variant\", $\"a.is_new\", $\"a.is_subscribed\", $\"b.category\")\n",
    "    .as(\"a\")\n",
    "    .join(sticker_apply.as(\"b\"), $\"a.editor_sid\" === $\"b.editor_sid\" && $\"a.category\" === $\"b.category\", \"left\")\n",
    "    .select($\"a.date\", $\"a.variant\", $\"a.is_new\", $\"a.is_subscribed\", $\"a.category\", $\"a.editor_sid\".as(\"try\"), $\"b.editor_sid\".as(\"apply\"))\n",
    "    .groupBy($\"date\", $\"category\", $\"variant\")\n",
    "    .agg(countDistinct($\"try\").as(\"try_sid\"), countDistinct($\"apply\").as(\"apply_sid\"))\n",
    "    .groupBy($\"category\", $\"variant\")\n",
    "    .agg(avg($\"try_sid\"), avg($\"apply_sid\"))\n",
    "//     .show(100000,false)\n",
    "\n",
    "\n",
    "\n",
    "val apply_editor_done = exp\n",
    "    .as(\"a\")\n",
    "    .join(sticker_apply.as(\"b\"), $\"a.device_id\" === $\"b.device_id\" && $\"a.timestamp\" <= $\"b.timestamp\", \"inner\")\n",
    "    .select(to_date($\"b.timestamp\").as(\"date\"), $\"b.device_id\", $\"b.editor_sid\", $\"a.variant\", $\"a.is_new\", $\"a.is_subscribed\")\n",
    "    .as(\"a\")\n",
    "    .join(editor_done.as(\"b\"), $\"a.editor_sid\" === $\"b.editor_sid\", \"left\")\n",
    "    .select($\"a.date\", $\"a.variant\", $\"a.editor_sid\".as(\"apply\"), $\"b.editor_sid\".as(\"done\"))\n",
    "    .groupBy($\"date\", $\"variant\")\n",
    "    .agg(countDistinct($\"apply\").as(\"apply\"), countDistinct($\"done\").as(\"done\"))\n",
    "    .groupBy($\"variant\")\n",
    "    .agg(avg($\"apply\"), avg($\"done\"))\n",
    "    .orderBy($\"variant\")\n",
    "//     .show(1000,false)\n",
    "\n",
    "\n",
    " category_open.as(\"a\").join(exp.as(\"b\"), $\"a.device_id\"===$\"b.device_id\" && $\"a.timestamp\" >= $\"b.timestamp\", \"inner\")\n",
    ".select($\"a.timestamp\", $\"a.editor_sid\", $\"b.variant\", $\"a.source\")\n",
    ".groupBy(to_date($\"timestamp\").as(\"date\"), $\"variant\", $\"source\")\n",
    ".agg(countDistinct($\"editor_sid\").as(\"sid\"))\n",
    ".groupBy($\"variant\", $\"source\")\n",
    ".agg(avg($\"sid\"))\n",
    ".show(10000,false)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.hadoop.fs.{Path, FileSystem}\n",
       "import org.apache.hadoop.conf.Configuration\n",
       "res12: Boolean = true\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// import org.apache.hadoop.fs.{Path, FileSystem}\n",
    "// import org.apache.hadoop.conf.Configuration\n",
    "\n",
    "// FileSystem.get(new Configuration()).delete(new Path(\"/user/nare.silanyan/exp\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|               app|\n",
      "+------------------+\n",
      "|               app|\n",
      "|com.picsart.studio|\n",
      "+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "installs: Unit = ()\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+----------------------+\n",
      "|variant         |avg(similar_try_sid)|avg(similar_apply_sid)|\n",
      "+----------------+--------------------+----------------------+\n",
      "|similar stickers|11894.333333333334  |5372.4                |\n",
      "|original        |10.428571428571429  |4.5                   |\n",
      "+----------------+--------------------+----------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "object_action_exp: org.apache.spark.sql.DataFrame = [date: date, device_id: string ... 4 more fields]\n",
       "sticker_apply_similar: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [timestamp: timestamp, category: string ... 3 more fields]\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// category_open.as(\"a\").\n",
    "// join(exp.as(\"b\"), $\"a.device_id\" === $\"b.device_id\" && $\"a.timestamp\" >= $\"b.timestamp\", \"inner\").\n",
    "//     select(to_date($\"a.timestamp\").as(\"date\"), $\"a.device_id\", $\"a.editor_sid\",$\"b.variant\", $\"a.source\", $\"b.is_new\", $\"b.is_subscribed\").\n",
    "//     groupBy($\"date\", $\"variant\", $\"source\", $\"b.is_new\", $\"b.is_subscribed\").\n",
    "//     agg(\n",
    "//         countDistinct($\"device_id\").as(\"category_open_dv\"), \n",
    "//         countDistinct($\"editor_sid\").as(\"category_open_sid\")).show(1000000,false)\n",
    "\n",
    "\n",
    "// sticker_try.as(\"a\").\n",
    "//     join(exp.as(\"b\"), $\"a.device_id\" === $\"b.device_id\" && $\"a.timestamp\" >= $\"b.timestamp\", \"inner\").\n",
    "//     select(to_date($\"a.timestamp\").as(\"date\"), $\"a.device_id\", $\"a.editor_sid\",$\"b.variant\", $\"b.is_new\", $\"b.is_subscribed\").\n",
    "//     groupBy($\"date\", $\"variant\", $\"is_new\", $\"is_subscribed\").\n",
    "//     agg(countDistinct($\"device_id\").as(\"try_dv\"), count($\"editor_sid\").as(\"try_sid\"), countDistinct($\"editor_sid\").as(\"sid\")).show(100000,false)\n",
    "\n",
    "val object_action_exp = getEvent(\"com.picsart.studio\", \"add_object_action\", from, to).\n",
    "    filter($\"object_type\"===\"sticker\" && $\"origin\"===\"editor\" && $\"action\" === \"similar\").\n",
    "    select($\"timestamp\", $\"device_id\", $\"editor_sid\").as(\"a\").\n",
    "    join(exp.as(\"b\"), $\"a.device_id\" === $\"b.device_id\" && $\"a.timestamp\" >= $\"b.timestamp\", \"inner\").\n",
    "    select(to_date($\"a.timestamp\").as(\"date\"), $\"a.device_id\", $\"a.editor_sid\",$\"b.variant\", $\"b.is_new\", $\"b.is_subscribed\")\n",
    "\n",
    "//     object_action_exp.groupBy($\"date\", $\"variant\", $\"is_new\", $\"is_subscribed\").\n",
    "//     agg(countDistinct($\"device_id\").as(\"similar_dv\"), count($\"editor_sid\").as(\"similar_sid\"), countDistinct($\"editor_sid\").as(\"sid\")).show(100000,false)\n",
    "\n",
    "val sticker_apply_similar = sticker_apply.filter($\"source\" === \"similar\")\n",
    "\n",
    "object_action_exp.as(\"a\").join(sticker_apply_similar.as(\"b\"), $\"a.editor_sid\" === $\"b.editor_sid\", \"left\")\n",
    ".select($\"a.date\", $\"a.variant\", $\"a.is_new\", $\"a.is_subscribed\", $\"a.editor_sid\".as(\"similar_try_sid\"), $\"b.editor_sid\".as(\"similar_apply_sid\"))\n",
    ".groupBy($\"date\", $\"variant\")\n",
    ".agg(countDistinct($\"similar_try_sid\").as(\"similar_try_sid\"), countDistinct($\"similar_apply_sid\").as(\"similar_apply_sid\"))\n",
    ".groupBy($\"variant\")\n",
    ".agg(avg($\"similar_try_sid\"), avg($\"similar_apply_sid\"))\n",
    ".show(10000000,false)\n",
    "\n",
    "\n",
    "\n",
    "// sticker_apply.as(\"a\").\n",
    "//     join(exp.as(\"b\"), $\"a.device_id\" === $\"b.device_id\" && $\"a.timestamp\" >= $\"b.timestamp\", \"inner\").\n",
    "//     select(to_date($\"a.timestamp\").as(\"date\"), $\"a.device_id\", $\"a.editor_sid\",$\"b.variant\", $\"a.source\", \n",
    "//            (when($\"a.source\"===\"similar\", lit(\"similar\")).otherwise(lit(\"no_similar\"))).as(\"new_source\"), $\"b.is_new\", $\"b.is_subscribed\").\n",
    "// filter($\"new_source\" === \"no_similar\").\n",
    "//     groupBy($\"date\", $\"variant\", $\"new_source\", $\"is_new\", $\"is_subscribed\").\n",
    "//     agg(countDistinct($\"device_id\").as(\"dv\"),countDistinct($\"editor_sid\").as(\"sid\"), count($\"editor_sid\").as(\"applies\")).show(100000,false)\n",
    "\n",
    "\n",
    "// sticker_apply.groupBy($\"category\").agg(countDistinct($\"editor_sid\").as(\"apply_sid\")).orderBy($\"apply_sid\".desc).show(1000000,false)\n",
    "\n",
    "// sticker_try.groupBy($\"category\").agg(countDistinct($\"editor_sid\").as(\"sid\")).orderBy($\"sid\".desc).show(1000000,false)\n",
    "\n",
    "// val applies_per_applier = sticker_apply.as(\"a\").\n",
    "//     join(exp.as(\"b\"), $\"a.device_id\" === $\"b.device_id\" && $\"a.timestamp\" >= $\"b.timestamp\", \"inner\").\n",
    "//     select(to_date($\"a.timestamp\").as(\"date\"), $\"a.device_id\", $\"a.editor_sid\",$\"b.variant\",$\"b.is_new\", $\"b.is_subscribed\").\n",
    "//     groupBy($\"date\", $\"variant\", $\"is_new\", $\"is_subscribed\").\n",
    "//     agg(countDistinct($\"device_id\").as(\"dv\"),countDistinct($\"editor_sid\").as(\"sid\"), count($\"editor_sid\").as(\"applies\")).show(100000,false)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+-------------------------+-----------------------+\n",
      "|purchase_dd|variant         |count(DISTINCT device_id)|count(DISTINCT sub_sid)|\n",
      "+-----------+----------------+-------------------------+-----------------------+\n",
      "|2019-07-19 |original        |3                        |3                      |\n",
      "|2019-07-13 |similar stickers|4                        |4                      |\n",
      "|2019-07-22 |similar stickers|5                        |5                      |\n",
      "|2019-07-20 |similar stickers|4                        |4                      |\n",
      "|2019-07-10 |original        |3                        |3                      |\n",
      "|2019-07-17 |similar stickers|2                        |2                      |\n",
      "|2019-07-12 |original        |4                        |4                      |\n",
      "|2019-07-22 |original        |8                        |8                      |\n",
      "|2019-07-15 |original        |6                        |6                      |\n",
      "|2019-07-23 |similar stickers|6                        |6                      |\n",
      "|2019-07-12 |similar stickers|4                        |4                      |\n",
      "|2019-07-18 |similar stickers|4                        |4                      |\n",
      "|2019-07-23 |original        |4                        |4                      |\n",
      "|2019-07-17 |original        |4                        |4                      |\n",
      "|2019-07-20 |original        |4                        |4                      |\n",
      "|2019-07-16 |similar stickers|5                        |5                      |\n",
      "|2019-07-21 |original        |4                        |4                      |\n",
      "|2019-07-19 |similar stickers|5                        |5                      |\n",
      "|2019-07-21 |similar stickers|7                        |7                      |\n",
      "|2019-07-11 |original        |6                        |6                      |\n",
      "|2019-07-18 |original        |3                        |3                      |\n",
      "|2019-07-14 |original        |3                        |3                      |\n",
      "|2019-07-16 |original        |7                        |7                      |\n",
      "|2019-07-13 |original        |5                        |5                      |\n",
      "|2019-07-14 |similar stickers|4                        |4                      |\n",
      "+-----------+----------------+-------------------------+-----------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "done: org.apache.spark.sql.DataFrame = [done_timestamp: timestamp, device_id: string ... 5 more fields]\n",
       "users: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [device_id: string, order_id: string]\n",
       "orders: org.apache.spark.sql.DataFrame = [_id: string, purchase_dd: date ... 3 more fields]\n",
       "users_order: org.apache.spark.sql.DataFrame = [device_id: string, _id: string ... 4 more fields]\n",
       "backend_done: org.apache.spark.sql.DataFrame = [sub_sid: string, device_id: string ... 4 more fields]\n"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "var done = getEvent(\"com.picsart.studio\",\"subscription_done\", from, to).\n",
    "    select($\"session_id\", $\"device_id\",$\"sub_sid\",$\"source\", $\"source_sid\",$\"timestamp\".as(\"done_timestamp\"),$\"platform\",$\"direct_purchase\", $\"sub_source\").\n",
    "    withColumn(\"N\", row_number().over(Window.partitionBy($\"device_id\", to_date($\"done_timestamp\")).orderBy($\"done_timestamp\".desc))).\n",
    "    filter($\"N\" === 1).drop($\"N\").    \n",
    "    distinct().\n",
    "    filter($\"source\".like(\"%sticker%\") && $\"platform\" === \"apple\").\n",
    "    select($\"done_timestamp\", $\"device_id\", $\"sub_sid\", $\"source\", $\"source_sid\").as(\"a\").\n",
    "    join(exp.as(\"b\"), $\"a.device_id\"=== $\"b.device_id\" && $\"a.done_timestamp\">= $\"b.timestamp\", \"inner\").\n",
    "    select($\"a.done_timestamp\", $\"a.device_id\", $\"a.sub_sid\", $\"a.source\", $\"a.source_sid\", $\"b.variant\", $\"b.is_new\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "//------------------------------------------------------------------------------ BACKEND DATA\n",
    "var users = sqlContext.read.parquet(\"/analytics/entities/users_orders\").filter($\"device_id\". isNotNull).select($\"device_id\", $\"order_id\").distinct()\n",
    "\n",
    "var orders = sqlContext.read.parquet(\"/analytics/entities/orders\").\n",
    "    withColumn(\"purchase_dd\", to_date($\"purchase_date\")).\n",
    "    withColumn(\"expire_dd\", to_date($\"expire_date\")).\n",
    "    withColumn(\"platform\", when(($\"market\" === \"google\") || ($\"market\" === \"wechat\"), lit(\"android\")).otherwise(lit(\"apple\"))).\n",
    "    filter($\"platform\"===\"apple\").\n",
    "    filter($\"purchase_dd\" <= to.toString().slice(0, 10) && $\"purchase_dd\" >= from.toString().slice(0, 10)).\n",
    "    select($\"_id\", $\"purchase_dd\", $\"expire_dd\", $\"renewals\", $\"platform\")\n",
    "\n",
    "var users_order = orders.as(\"a\").join(users.as(\"b\"), $\"a._id\" === $\"b.order_id\", \"inner\").\n",
    "    select($\"b.device_id\", $\"a._id\", $\"purchase_dd\", explode($\"a.renewals\").as(\"ev\")).\n",
    "    select($\"device_id\", $\"_id\", $\"purchase_dd\", $\"ev.purchaseDate\".as(\"RN_purchase\"), $\"ev.paymentStatus\".as(\"RN_payment\")).\n",
    "    withColumn(\"N\", row_number().over(Window.partitionBy($\"_id\").orderBy($\"rn_purchase\")))\n",
    "\n",
    "//------------------------------------------------------------------------------ FT's AND PAIDS BY SOURCE (from subscription done)\n",
    "var backend_done = users_order.as(\"a\").\n",
    "    join(done.as(\"b\"), $\"a.device_id\" === $\"b.device_id\" && $\"a.purchase_dd\" === to_date($\"b.done_timestamp\"), \"inner\").\n",
    "    select($\"b.sub_sid\", $\"b.device_id\", $\"a.purchase_dd\", $\"b.source\", $\"b.variant\", $\"b.is_new\")\n",
    "\n",
    "\n",
    "backend_done.groupBy($\"purchase_dd\", $\"variant\").agg(countDistinct($\"device_id\"), countDistinct($\"sub_sid\"))\n",
    ".show(1000000,false)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = null\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " val df: DataFrame = null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "retention: (dd: org.joda.time.DateTime)Unit\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Retention\n",
    "\n",
    "\n",
    "\n",
    "def retention(dd: DateTime): Unit={\n",
    "    \n",
    "    val new_user = sqlContext.read.parquet(\"/user/nare.silanyan/exp\").\n",
    "    filter($\"is_new\"=== true && to_date($\"timestamp\")=== dd.toString.slice(0,10)).\n",
    "    select($\"timestamp\", $\"is_subscribed\", $\"device_id\", $\"variant\")\n",
    "\n",
    "\n",
    "\n",
    "val sticker_apply = getEvent(\"com.picsart.studio\", \"edit_sticker_apply\", dd, dd).\n",
    "    filter($\"origin\" === \"editor\" && $\"platform\" === \"apple\" && $\"device_id\".isNotNull).\n",
    "    select($\"timestamp\", $\"device_id\", $\"category\", $\"source\").distinct()\n",
    "\n",
    "\n",
    "val sticker_apply_1 = getEvent(\"com.picsart.studio\", \"edit_sticker_apply\", dd.plusDays(7), dd.plusDays(7)).\n",
    "filter($\"origin\"===\"editor\" && $\"platform\" === \"apple\" && $\"device_id\".isNotNull).\n",
    "select(to_date($\"timestamp\").as(\"apply_date_1\"), $\"device_id\", $\"category\").distinct()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "val new_sticker_apply = sticker_apply.as(\"a\").\n",
    "    join(new_user.as(\"b\"), $\"a.device_id\" === $\"b.device_id\" && $\"a.timestamp\" >= $\"b.timestamp\", \"inner\").\n",
    "    select($\"b.variant\", $\"a.device_id\".as(\"apply_dv_0\"), to_date($\"a.timestamp\").as(\"apply_date\"), $\"a.category\")\n",
    "    \n",
    "val new_sticker_apply_0_1 = new_sticker_apply\n",
    "    .as(\"a\")\n",
    "    .join(sticker_apply_1.as(\"b\"), $\"a.apply_dv_0\" === $\"b.device_id\" /*&& $\"a.category\" === $\"b.category\"*/, \"left\")\n",
    "    .select($\"a.variant\", $\"a.apply_dv_0\", $\"a.apply_date\", $\"b.apply_date_1\", $\"b.device_id\".as(\"apply_dv_1\"), $\"a.category\")\n",
    "    .groupBy($\"apply_date\", $\"variant\", $\"category\")\n",
    "    .agg(countDistinct($\"apply_dv_0\").as(\"apply_dv_0\"), countDistinct($\"apply_dv_1\").as(\"apply_dv_1\"))\n",
    "    .withColumn(\"join_condition\", lit(\"not_category\"))\n",
    "    \n",
    "//     df.unionAll(new_sticker_apply_0_1)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    " \n",
    "    \n",
    "val similar_new_sticker_apply = sticker_apply.filter($\"source\" === \"similar\").as(\"a\").\n",
    "    join(new_user.as(\"b\"), $\"a.device_id\" === $\"b.device_id\" && $\"a.timestamp\" >= $\"b.timestamp\", \"inner\").\n",
    "    select($\"b.variant\", $\"a.device_id\".as(\"apply_dv_0\"), to_date($\"a.timestamp\").as(\"apply_date\"))\n",
    "       \n",
    "val similar_sticker_apply_1 = getEvent(\"com.picsart.studio\", \"edit_sticker_apply\", dd.plusDays(7), dd.plusDays(7)).\n",
    "filter($\"origin\"===\"editor\" && $\"platform\" === \"apple\" && $\"device_id\".isNotNull /*&& $\"source\" === \"similar\"*/).\n",
    "select(to_date($\"timestamp\").as(\"apply_date_1\"), $\"device_id\").distinct()\n",
    "    \n",
    "    \n",
    "val similar_new_sticker_apply_0_1 = similar_new_sticker_apply\n",
    "    .as(\"a\")\n",
    "    .join(similar_sticker_apply_1.as(\"b\"), $\"a.apply_dv_0\" === $\"b.device_id\" , \"left\")\n",
    "    .select($\"a.variant\", $\"a.apply_dv_0\", $\"a.apply_date\", $\"b.apply_date_1\", $\"b.device_id\".as(\"apply_dv_1\"))\n",
    "    .groupBy($\"apply_date\", $\"variant\")\n",
    "    .agg(countDistinct($\"apply_dv_0\").as(\"apply_dv_0\"), countDistinct($\"apply_dv_1\").as(\"apply_dv_1\"))\n",
    "        .withColumn(\"join_condition\", lit(\"not_category\"))\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    " \n",
    "//     return new_sticker_apply_0_1\n",
    "//     return similar_new_sticker_apply_0_1\n",
    "    \n",
    "    \n",
    "// new_sticker_apply_0_1\n",
    "//     .write.mode(org.apache.spark.sql.SaveMode.Append)\n",
    "//     .parquet(\"/user/nare.silanyan/7_day_retention_sticker_apply_applied\")\n",
    "    \n",
    "// similar_new_sticker_apply_0_1\n",
    "//     .write.mode(org.apache.spark.sql.SaveMode.Append)\n",
    "//     .parquet(\"/user/nare.silanyan/7_day_retention_similar_sticker_apply\")\n",
    "    \n",
    "//     publish(new_sticker_apply_0_1, \"7_day_retention_sticker_apply_category_applied\", true)\n",
    "//     publish(similar_new_sticker_apply_0_1, \"7_day_retention_similar_sticker_apply_category_applied\", true)\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished for: 2019-07-09  Started for: 2019-07-10\n",
      "Finished for: 2019-07-10  Started for: 2019-07-11\n",
      "Finished for: 2019-07-11  Started for: 2019-07-12\n",
      "Finished for: 2019-07-12  Started for: 2019-07-13\n",
      "Finished for: 2019-07-13  Started for: 2019-07-14\n",
      "Finished for: 2019-07-14  Started for: 2019-07-15\n",
      "Finished for: 2019-07-15  Started for: 2019-07-16\n",
      "Finished for: 2019-07-16  Started for: 2019-07-17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "from_ret: org.joda.time.DateTime = 2019-07-09T00:00:00.000Z\n",
       "to_ret: org.joda.time.DateTime = 2019-07-16T00:00:00.000Z\n",
       "dd: org.joda.time.DateTime = 2019-07-17T00:00:00.000Z\n"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val from_ret = DateTime.parse(\"2019-07-09\")\n",
    "val to_ret = DateTime.parse(\"2019-07-16\")\n",
    "var dd = from_ret\n",
    "\n",
    "\n",
    "while(dd.isBefore(to_ret.plusDays(1))){\n",
    "    retention(dd)\n",
    "    println(\"Finished for\" + \": \" + dd.toString.slice(0,10) + \"  \" + \"Started for\" + \": \" + dd.plusDays(1).toString.slice(0,10))\n",
    "    dd = dd.plusDays(1)\n",
    "\n",
    "}\n",
    "\n",
    "// retention(dd).show(100,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+----------+\n",
      "|variant         |apply_dv_0|apply_dv_1|\n",
      "+----------------+----------+----------+\n",
      "|original        |2.0       |0.0       |\n",
      "|similar stickers|302.75    |24.0      |\n",
      "+----------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlContext.read.parquet(\"/user/nare.silanyan/7_day_retention_similar_sticker_apply\")\n",
    ".filter($\"join_condition\" === \"not_category\")\n",
    ".select($\"apply_date\", $\"variant\", $\"apply_dv_0\", $\"apply_dv_1\")\n",
    ".groupBy($\"apply_date\", $\"variant\")\n",
    ".agg(sum($\"apply_dv_0\").as(\"apply_dv_0\"), sum($\"apply_dv_1\").as(\"apply_dv_1\"))\n",
    ".groupBy($\"variant\")\n",
    ".agg(avg($\"apply_dv_0\").as(\"apply_dv_0\"), avg($\"apply_dv_1\").as(\"apply_dv_1\"))\n",
    ".orderBy($\"variant\",$\"apply_dv_0\".desc)\n",
    ".show(100,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.hadoop.fs.{Path, FileSystem}\n",
       "import org.apache.hadoop.conf.Configuration\n",
       "res14: Boolean = true\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "// import org.apache.hadoop.fs.{Path, FileSystem}\n",
    "// import org.apache.hadoop.conf.Configuration\n",
    "// FileSystem.get(new Configuration).delete(new Path(\"/user/nare.silanyan/7_day_retention_sticker_apply_category_applied\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "retention: (dd: org.joda.time.DateTime, tt: org.joda.time.DateTime)org.apache.spark.sql.DataFrame\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def retention(dd: DateTime, tt : DateTime): DataFrame={\n",
    "    \n",
    "    val new_user = sqlContext.read.parquet(\"/user/nare.silanyan/exp\").\n",
    "    filter($\"is_new\"=== true && to_date($\"timestamp\")>= dd.toString.slice(0,10) && to_date($\"timestamp\")<= tt.toString.slice(0,10)).\n",
    "    select($\"timestamp\", $\"is_subscribed\", $\"device_id\", $\"variant\")\n",
    "\n",
    "\n",
    "\n",
    "val sticker_apply = getEvent(\"com.picsart.studio\", \"edit_sticker_apply\", dd, tt).\n",
    "    filter($\"origin\" === \"editor\" && $\"platform\" === \"apple\" && $\"device_id\".isNotNull).\n",
    "    select($\"timestamp\", $\"device_id\", $\"category\", $\"source\").distinct()\n",
    "\n",
    "\n",
    "val sticker_apply_1 = getEvent(\"com.picsart.studio\", \"edit_sticker_apply\", dd.plusDays(7), dd.plusDays(14)).\n",
    "filter($\"origin\"===\"editor\" && $\"platform\" === \"apple\" && $\"device_id\".isNotNull).\n",
    "select($\"device_id\", $\"category\").distinct()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "val new_sticker_apply = sticker_apply.as(\"a\").\n",
    "    join(new_user.as(\"b\"), $\"a.device_id\" === $\"b.device_id\" && to_date($\"a.timestamp\") === to_date($\"b.timestamp\"), \"inner\").\n",
    "    select($\"b.variant\", $\"a.device_id\".as(\"apply_dv_0\"), to_date($\"a.timestamp\").as(\"apply_date\"), $\"a.category\")\n",
    "    \n",
    "val new_sticker_apply_0_1 = new_sticker_apply\n",
    "    .as(\"a\")\n",
    "    .join(sticker_apply_1.as(\"b\"), $\"a.apply_dv_0\" === $\"b.device_id\" /*&& $\"a.category\" === $\"b.category\"*/, \"left\")\n",
    "    .select($\"a.variant\", $\"a.apply_dv_0\",  $\"b.device_id\".as(\"apply_dv_week\"), $\"a.category\")\n",
    "    .groupBy($\"variant\", $\"category\")\n",
    "    .agg(countDistinct($\"apply_dv_0\"), countDistinct($\"apply_dv_week\"))\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    " \n",
    "    \n",
    "val similar_new_sticker_apply = sticker_apply.filter($\"source\" === \"similar\").as(\"a\").\n",
    "    join(new_user.as(\"b\"), $\"a.device_id\" === $\"b.device_id\" && $\"a.timestamp\" >= $\"b.timestamp\", \"inner\").\n",
    "    select($\"b.variant\", $\"a.device_id\".as(\"apply_dv_0\"), to_date($\"a.timestamp\").as(\"apply_date\"))\n",
    "       \n",
    "val similar_sticker_apply_1 = getEvent(\"com.picsart.studio\", \"edit_sticker_apply\", dd.plusDays(7), dd.plusDays(14)).\n",
    "filter($\"origin\"===\"editor\" && $\"platform\" === \"apple\" && $\"device_id\".isNotNull && $\"source\" === \"similar\").\n",
    "select(to_date($\"timestamp\").as(\"apply_date_1\"), $\"device_id\").distinct()\n",
    "    \n",
    "    \n",
    "val similar_new_sticker_apply_0_1 = similar_new_sticker_apply\n",
    "    .as(\"a\")\n",
    "    .join(similar_sticker_apply_1.as(\"b\"), $\"a.apply_dv_0\" === $\"b.device_id\" , \"left\")\n",
    "    .select($\"a.variant\", $\"a.apply_dv_0\", $\"a.apply_date\", $\"b.apply_date_1\", $\"b.device_id\".as(\"apply_dv_1\"))\n",
    "    .groupBy($\"variant\")\n",
    "    .agg(countDistinct($\"apply_dv_0\"), countDistinct($\"apply_dv_1\"))\n",
    "        \n",
    "    \n",
    "    \n",
    " \n",
    "//     return new_sticker_apply_0_1\n",
    "    return similar_new_sticker_apply_0_1\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------------+--------------------------+\n",
      "|variant         |count(DISTINCT apply_dv_0)|count(DISTINCT apply_dv_1)|\n",
      "+----------------+--------------------------+--------------------------+\n",
      "|similar stickers|2635                      |456                       |\n",
      "|original        |1                         |0                         |\n",
      "+----------------+--------------------------+--------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "from_ret: org.joda.time.DateTime = 2019-07-09T00:00:00.000Z\n",
       "to_ret: org.joda.time.DateTime = 2019-07-15T00:00:00.000Z\n",
       "dd: org.joda.time.DateTime = 2019-07-09T00:00:00.000Z\n",
       "tt: org.joda.time.DateTime = 2019-07-15T00:00:00.000Z\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val from_ret = DateTime.parse(\"2019-07-09\")\n",
    "val to_ret = DateTime.parse(\"2019-07-15\")\n",
    "\n",
    "val dd = from_ret\n",
    "val tt = to_ret\n",
    "\n",
    "retention(dd, tt).show(100,false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "from: org.joda.time.DateTime = 2019-08-30T00:00:00.000Z\n",
       "sticker_apply_subcategory: org.apache.spark.sql.DataFrame = [subcategory: string, count(DISTINCT editor_sid): bigint]\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val from = DateTime.parse(\"2019-08-30\")\n",
    "\n",
    "\n",
    "val sticker_apply_subcategory = getEvent(\"com.picsart.studio\", \"edit_sticker_apply\", from, from)\n",
    ".filter($\"origin\"===\"editor\")\n",
    ".select(to_date($\"timestamp\").as(\"apply_date\"), $\"editor_sid\", $\"subcategory\")\n",
    ".groupBy($\"subcategory\")\n",
    ".agg(countDistinct($\"editor_sid\"))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
